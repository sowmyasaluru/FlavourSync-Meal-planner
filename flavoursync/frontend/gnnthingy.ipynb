{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Red Lentil Soup with Chicken and Turnips', [{'name': 'diced additional toppings: avocado', 'amount': 8.0, 'unit': 'servings'}, {'name': 'diced carrots', 'amount': 3.0, 'unit': 'medium'}, {'name': 'diced celery stalks', 'amount': 3.0, 'unit': ''}, {'name': 'shredded chicken breast', 'amount': 280.0, 'unit': 'g'}, {'name': 'italian flat leaf parsley', 'amount': 30.0, 'unit': 'g'}, {'name': 'garlic', 'amount': 6.0, 'unit': 'cloves'}, {'name': 'olive oil', 'amount': 2.0, 'unit': 'Tbsps'}, {'name': 'canned tomatoes', 'amount': 793.787, 'unit': 'g'}, {'name': 'red dried lentils', 'amount': 360.0, 'unit': 'g'}, {'name': 'black salt and pepper', 'amount': 8.0, 'unit': 'servings'}, {'name': 'diced turnip', 'amount': 1.0, 'unit': 'large'}, {'name': 'vegetable stock', 'amount': 1.88, 'unit': 'l'}, {'name': 'yellow diced onion', 'amount': 1.0, 'unit': 'medium'}]), ('Asparagus and Pea Soup: Real Convenience Food', [{'name': 'frozen asparagus', 'amount': 1.0, 'unit': 'bag'}, {'name': 'evoo', 'amount': 1.0, 'unit': 'Tbsp'}, {'name': 'garlic', 'amount': 2.0, 'unit': 'cloves'}, {'name': 'onion', 'amount': 0.5, 'unit': ''}, {'name': 'frozen peas', 'amount': 290.0, 'unit': 'g'}, {'name': 'low sodium vegetable broth', 'amount': 1.0, 'unit': 'box'}])]\n",
      "850\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Load JSON data\n",
    "with open('all_recipes.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Inspect a few entries to understand the structure\n",
    "print(list(data.items())[:2])\n",
    "print(len(data.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'taco seasoning', 'amount': 2.0, 'unit': 'Tbsps'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize sets for unique recipes and ingredients\n",
    "recipes = list(data.keys())\n",
    "ingredients = set()\n",
    "\n",
    "# Extract unique ingredients\n",
    "for recipe, ingredient_list in data.items():\n",
    "    for ingredient in ingredient_list:\n",
    "        ingredients.add(ingredient[\"name\"])  # Add ingredient name to the set\n",
    "\n",
    "ingredients = list(ingredients)  # Convert to list for easier indexing\n",
    "print(ingredient)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store recipe-ingredient edges\n",
    "edges = []\n",
    "\n",
    "# Generate edges (recipe, ingredient) for the graph\n",
    "for recipe, ingredient_list in data.items():\n",
    "    for ingredient in ingredient_list:\n",
    "        ingredient_name = ingredient[\"name\"]\n",
    "        edges.append((recipe, ingredient_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings for recipe and ingredient nodes\n",
    "recipe_to_idx = {recipe: idx for idx, recipe in enumerate(recipes)}\n",
    "ingredient_to_idx = {ingredient: idx + len(recipes) for idx, ingredient in enumerate(ingredients)}  # Offset by recipe count\n",
    "\n",
    "# Convert edges to index pairs for easier use in a GNN\n",
    "indexed_edges = [(recipe_to_idx[recipe], ingredient_to_idx[ingredient]) for recipe, ingredient in edges]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Convert edges to PyTorch tensors\n",
    "edge_index = torch.tensor(indexed_edges, dtype=torch.long).t().contiguous()\n",
    "\n",
    "# Create a PyTorch Geometric data object\n",
    "data = Data(edge_index=edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPREPROCESSING PART IS DONE\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PREPROCESSING PART IS DONE\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def get_cosine_similarity(embedding_a, embedding_b):\n",
    "    return cosine_similarity(embedding_a.reshape(1, -1), embedding_b.reshape(1, -1))[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50, Loss: 1.1198545694351196\n",
      "Epoch 2/50, Loss: 1.06256103515625\n",
      "Epoch 3/50, Loss: 0.9156192541122437\n",
      "Epoch 4/50, Loss: 0.8262745141983032\n",
      "Epoch 5/50, Loss: 0.7702227830886841\n",
      "Epoch 6/50, Loss: 0.7072864770889282\n",
      "Epoch 7/50, Loss: 0.6375679969787598\n",
      "Epoch 8/50, Loss: 0.5778673887252808\n",
      "Epoch 9/50, Loss: 0.5344282388687134\n",
      "Epoch 10/50, Loss: 0.4904997646808624\n",
      "Epoch 11/50, Loss: 0.43910449743270874\n",
      "Epoch 12/50, Loss: 0.40081557631492615\n",
      "Epoch 13/50, Loss: 0.37692660093307495\n",
      "Epoch 14/50, Loss: 0.3432007133960724\n",
      "Epoch 15/50, Loss: 0.3148876428604126\n",
      "Epoch 16/50, Loss: 0.3012235164642334\n",
      "Epoch 17/50, Loss: 0.2782951891422272\n",
      "Epoch 18/50, Loss: 0.25947195291519165\n",
      "Epoch 19/50, Loss: 0.2490740865468979\n",
      "Epoch 20/50, Loss: 0.23184284567832947\n",
      "Epoch 21/50, Loss: 0.2193581759929657\n",
      "Epoch 22/50, Loss: 0.21040451526641846\n",
      "Epoch 23/50, Loss: 0.19748157262802124\n",
      "Epoch 24/50, Loss: 0.1901119500398636\n",
      "Epoch 25/50, Loss: 0.18227773904800415\n",
      "Epoch 26/50, Loss: 0.1739710122346878\n",
      "Epoch 27/50, Loss: 0.17002728581428528\n",
      "Epoch 28/50, Loss: 0.16293689608573914\n",
      "Epoch 29/50, Loss: 0.15924550592899323\n",
      "Epoch 30/50, Loss: 0.15563412010669708\n",
      "Epoch 31/50, Loss: 0.15092845261096954\n",
      "Epoch 32/50, Loss: 0.1484534740447998\n",
      "Epoch 33/50, Loss: 0.14502781629562378\n",
      "Epoch 34/50, Loss: 0.1412254422903061\n",
      "Epoch 35/50, Loss: 0.13877186179161072\n",
      "Epoch 36/50, Loss: 0.13490356504917145\n",
      "Epoch 37/50, Loss: 0.1314699649810791\n",
      "Epoch 38/50, Loss: 0.12855753302574158\n",
      "Epoch 39/50, Loss: 0.12450280040502548\n",
      "Epoch 40/50, Loss: 0.1218150332570076\n",
      "Epoch 41/50, Loss: 0.1184893324971199\n",
      "Epoch 42/50, Loss: 0.1156395897269249\n",
      "Epoch 43/50, Loss: 0.11315536499023438\n",
      "Epoch 44/50, Loss: 0.11059705168008804\n",
      "Epoch 45/50, Loss: 0.10853475332260132\n",
      "Epoch 46/50, Loss: 0.10643372684717178\n",
      "Epoch 47/50, Loss: 0.1045500785112381\n",
      "Epoch 48/50, Loss: 0.10277114808559418\n",
      "Epoch 49/50, Loss: 0.10090526938438416\n",
      "Epoch 50/50, Loss: 0.09927268326282501\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from torch_geometric.nn import GCNConv, SAGEConv, GATConv\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "# Define the GNN Model\n",
    "class RecipeGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(RecipeGNN, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_channels, hidden_channels)\n",
    "        self.conv2 = SAGEConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Initialize the GNN model, optimizer, and set up embeddings\n",
    "model = RecipeGNN(in_channels=64, hidden_channels=128, out_channels=64)  # Adjust input/output dimensions as needed\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy node features (use random or pre-trained features if available)\n",
    "x = torch.randn(len(recipes) + len(ingredients), 64)  # Random features for each node\n",
    "\n",
    "# Train the GNN model\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(x, edge_index)  # Forward pass\n",
    "    loss = F.mse_loss(out, x)   # Use MSE or other appropriate loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss.item()}\")\n",
    "\n",
    "# Function to recommend recipes based on multiple liked recipes\n",
    "def recommend_by_liked_recipes(liked_recipes_indices, embeddings, top_n=5):\n",
    "    liked_embeddings = [embeddings[idx] for idx in liked_recipes_indices]\n",
    "    profile = torch.stack(liked_embeddings).mean(dim=0)  # Average profile of liked recipes\n",
    "    \n",
    "    similarities = []\n",
    "    for idx, embedding in enumerate(embeddings[:len(recipe_to_idx)]):  # Only compare to recipe nodes\n",
    "        similarity = get_cosine_similarity(profile, embedding)\n",
    "        similarities.append((idx, similarity))\n",
    "    \n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    recommended_recipes = [recipes[idx] for idx, _ in similarities[:top_n]]\n",
    "    return recommended_recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Recipes: ['Fusilli With Zucchini Flowers, Ricotta and Saffron', 'Roast Cauliflower Salad with Green Beans and Cherry Tomatoes', 'Donkatsu - Korean Breaded Pork Cutlet', 'Luscious Palak Paneer', 'Chipotle Black Bean Soup with Avocado Cream']\n"
     ]
    }
   ],
   "source": [
    "liked_recipes=[\"Fusilli With Zucchini Flowers, Ricotta and Saffron\", \"Roast Cauliflower Salad with Green Beans and Cherry Tomatoes\"]\n",
    "liked_indices = [recipe_to_idx[recipe] for recipe in liked_recipes if recipe in recipe_to_idx]\n",
    "\n",
    "# Ensure we have exactly 2 liked recipes\n",
    "if len(liked_indices) == 2:\n",
    "    # Get recipe embeddings from the trained model\n",
    "    model.eval()\n",
    "    embeddings = model(x, edge_index).detach()  # Run model in eval mode, detach to prevent grad tracking\n",
    "\n",
    "    # Recommend based on the embeddings of liked recipes\n",
    "    recommended_recipes = recommend_by_liked_recipes(liked_indices, embeddings)\n",
    "    print(\"Recommended Recipes:\", recommended_recipes)\n",
    "else:\n",
    "    print(\"Please ensure you have two liked recipes in the list.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Node2Vec\n",
    "import torch\n",
    "\n",
    "# Assume edge_index and node_count are already defined\n",
    "node2vec = Node2Vec(edge_index, embedding_dim=64, walk_length=10, context_size=5, walks_per_node=10)\n",
    "loader = node2vec.loader(batch_size=128, shuffle=True)\n",
    "optimizer = torch.optim.Adam(node2vec.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(10):  # Adjust epoch count as needed\n",
    "    for pos_rw, neg_rw in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = node2vec.loss(pos_rw, neg_rw)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# Get embeddings for recipes and ingredients\n",
    "embeddings = node2vec.embedding.weight.data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_recipes(recipe_idx, embeddings, top_n=5):\n",
    "    recipe_embedding = embeddings[recipe_idx]\n",
    "    similarities = []\n",
    "\n",
    "    for idx, embedding in enumerate(embeddings):\n",
    "        if idx != recipe_idx:  # Exclude the input recipe itself\n",
    "            similarity = get_cosine_similarity(recipe_embedding, embedding)\n",
    "            similarities.append((idx, similarity))\n",
    "\n",
    "    # Sort recipes by similarity and get top-N recommendations\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    recommended_recipes = [idx for idx, sim in similarities[:top_n]]\n",
    "    return recommended_recipes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_by_ingredients(preferred_ingredients, ingredient_to_idx, embeddings, top_n=5):\n",
    "    # Get embeddings for preferred ingredients\n",
    "    ingredient_embeddings = [embeddings[ingredient_to_idx[ingredient]] for ingredient in preferred_ingredients]\n",
    "    \n",
    "    # Average embeddings to create an \"ingredient profile\"\n",
    "    ingredient_profile = sum(ingredient_embeddings) / len(ingredient_embeddings)\n",
    "    \n",
    "    # Calculate similarity between the ingredient profile and each recipe\n",
    "    similarities = []\n",
    "    for idx, recipe_embedding in enumerate(embeddings[:len(recipe_to_idx)]):  # Only consider recipe embeddings\n",
    "        similarity = get_cosine_similarity(ingredient_profile, recipe_embedding)\n",
    "        similarities.append((idx, similarity))\n",
    "\n",
    "    # Sort recipes by similarity and get top-N recommendations\n",
    "    similarities = sorted(similarities, key=lambda x: x[1], reverse=True)\n",
    "    recommended_recipes = [idx for idx, sim in similarities[:top_n]]\n",
    "    return recommended_recipes\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
